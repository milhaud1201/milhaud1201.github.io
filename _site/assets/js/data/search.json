[
  
  {
    "title": "PyCaret 맛보기",
    "url": "/posts/%ED%94%BC%EB%A7%88-%EC%9D%B8%EB%94%94%EC%96%B8-with-PyCaret/",
    "categories": "Programming, Machine Learning",
    "tags": "PyCaret, Tutorial",
    "date": "2022-11-26 18:23:28 +0900",
    





    
    "snippet": "피마 인디언 데이터셋 with PyCaretimport numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltimport koreanize_matplotlibData Load피마 인디언 당뇨병 데이터 셋df_pima = pd.read_csv(\"http://bi...",
    "content": "피마 인디언 데이터셋 with PyCaretimport numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltimport koreanize_matplotlibData Load피마 인디언 당뇨병 데이터 셋df_pima = pd.read_csv(\"http://bit.ly/data-diabetes-csv\")df_pima.shape(768, 9)PyCaret당뇨병 여부 분류 문제 적용시from pycaret.classification import *setupTrain data, Test data, Label, Target 등을 설정하는 부분이며, 데이터에 전처리 기법들을 적용 할 수 있음pycaret_models = setup(    session_id=42, # 랜덤 시드    data=df_pima, # Input Data    target=\"Outcome\", # Target    normalize=True, # 정규화 여부    normalize_method=\"minmax\", # 정규화 방식    transformation=True, # 데이터의 분포가 정규 분포에 더 가까워지도록 처리    fold_strategy=\"stratifiedkfold\",    use_gpu=True)            &nbsp;      Description      Value                  0      session_id      42              1      Target      Outcome              2      Target Type      Binary              3      Label Encoded      None              4      Original Data      (768, 9)              5      Missing Values      False              6      Numeric Features      7              7      Categorical Features      1              8      Ordinal Features      False              9      High Cardinality Features      False              10      High Cardinality Method      None              11      Transformed Train Set      (537, 24)              12      Transformed Test Set      (231, 24)              13      Shuffle Train-Test      True              14      Stratify Train-Test      False              15      Fold Generator      StratifiedKFold              16      Fold Number      10              17      CPU Jobs      -1              18      Use GPU      True              19      Log Experiment      False              20      Experiment Name      clf-default-name              21      USI      d7e1              22      Imputation Type      simple              23      Iterative Imputation Iteration      None              24      Numeric Imputer      mean              25      Iterative Imputation Numeric Model      None              26      Categorical Imputer      constant              27      Iterative Imputation Categorical Model      None              28      Unknown Categoricals Handling      least_frequent              29      Normalize      True              30      Normalize Method      minmax              31      Transformation      True              32      Transformation Method      yeo-johnson              33      PCA      False              34      PCA Method      None              35      PCA Components      None              36      Ignore Low Variance      False              37      Combine Rare Levels      False              38      Rare Level Threshold      None              39      Numeric Binning      False              40      Remove Outliers      False              41      Outliers Threshold      None              42      Remove Multicollinearity      False              43      Multicollinearity Threshold      None              44      Remove Perfect Collinearity      True              45      Clustering      False              46      Clustering Iteration      None              47      Polynomial Features      False              48      Polynomial Degree      None              49      Trignometry Features      False              50      Polynomial Threshold      None              51      Group Features      False              52      Feature Selection      False              53      Feature Selection Method      classic              54      Features Selection Threshold      None              55      Feature Interaction      False              56      Feature Ratio      False              57      Interaction Threshold      None              58      Fix Imbalance      False              59      Fix Imbalance Method      SMOTE      modelsmodels_list = models()models_list                  Name      Reference      Turbo              ID                                    lr      Logistic Regression      sklearn.linear_model._logistic.LogisticRegression      True              knn      K Neighbors Classifier      sklearn.neighbors._classification.KNeighborsCl...      True              nb      Naive Bayes      sklearn.naive_bayes.GaussianNB      True              dt      Decision Tree Classifier      sklearn.tree._classes.DecisionTreeClassifier      True              svm      SVM - Linear Kernel      sklearn.linear_model._stochastic_gradient.SGDC...      True              rbfsvm      SVM - Radial Kernel      sklearn.svm._classes.SVC      False              gpc      Gaussian Process Classifier      sklearn.gaussian_process._gpc.GaussianProcessC...      False              mlp      MLP Classifier      sklearn.neural_network._multilayer_perceptron....      False              ridge      Ridge Classifier      sklearn.linear_model._ridge.RidgeClassifier      True              rf      Random Forest Classifier      sklearn.ensemble._forest.RandomForestClassifier      True              qda      Quadratic Discriminant Analysis      sklearn.discriminant_analysis.QuadraticDiscrim...      True              ada      Ada Boost Classifier      sklearn.ensemble._weight_boosting.AdaBoostClas...      True              gbc      Gradient Boosting Classifier      sklearn.ensemble._gb.GradientBoostingClassifier      True              lda      Linear Discriminant Analysis      sklearn.discriminant_analysis.LinearDiscrimina...      True              et      Extra Trees Classifier      sklearn.ensemble._forest.ExtraTreesClassifier      True              lightgbm      Light Gradient Boosting Machine      lightgbm.sklearn.LGBMClassifier      True              dummy      Dummy Classifier      sklearn.dummy.DummyClassifier      True      pycaret에서 사용 가능한 모델 목록을 확인 할 수 있음compare_modelspc_clf_models = compare_models(    n_select=25, # 반환할 모델 개수    include=models_list.index.tolist())            &nbsp;      Model      Accuracy      AUC      Recall      Prec.      F1      Kappa      MCC      TT (Sec)                  gpc      Gaussian Process Classifier      0.7710      0.8098      0.5485      0.7305      0.6223      0.4645      0.4764      0.1060              et      Extra Trees Classifier      0.7691      0.8185      0.5643      0.7206      0.6279      0.4654      0.4755      0.4720              lr      Logistic Regression      0.7653      0.8368      0.5801      0.7055      0.6320      0.4632      0.4704      0.0260              rf      Random Forest Classifier      0.7615      0.8406      0.5693      0.6962      0.6202      0.4511      0.4591      0.4840              ada      Ada Boost Classifier      0.7597      0.8199      0.6061      0.6741      0.6360      0.4580      0.4609      0.0820              lightgbm      Light Gradient Boosting Machine      0.7597      0.8174      0.6333      0.6677      0.6437      0.4643      0.4691      0.9150              lda      Linear Discriminant Analysis      0.7596      0.8319      0.5798      0.6866      0.6223      0.4501      0.4565      0.0140              rbfsvm      SVM - Radial Kernel      0.7577      0.8418      0.5263      0.7080      0.6004      0.4331      0.4445      0.0300              ridge      Ridge Classifier      0.7559      0.0000      0.5693      0.6790      0.6151      0.4405      0.4457      0.0090              gbc      Gradient Boosting Classifier      0.7541      0.8396      0.6225      0.6566      0.6332      0.4502      0.4544      0.1010              knn      K Neighbors Classifier      0.7466      0.7800      0.5424      0.6789      0.6000      0.4183      0.4262      0.3870              mlp      MLP Classifier      0.7411      0.8044      0.5860      0.6483      0.6105      0.4186      0.4230      1.6220              svm      SVM - Linear Kernel      0.7299      0.0000      0.6284      0.6121      0.6119      0.4073      0.4127      0.0090              dt      Decision Tree Classifier      0.7187      0.6909      0.5965      0.6013      0.5919      0.3799      0.3848      0.0100              nb      Naive Bayes      0.6610      0.7666      0.1123      0.4499      0.1719      0.0824      0.1127      0.0090              dummy      Dummy Classifier      0.6499      0.5000      0.0000      0.0000      0.0000      0.0000      0.0000      0.0060              qda      Quadratic Discriminant Analysis      0.5529      0.5573      0.5865      0.4949      0.4345      0.1167      0.1724      0.0090      create_model여러 모델이 아닌 하나의 모델에 대해서 setup 설정으로 학습 및 결과 확인clf_lgbm = create_model(\"lightgbm\")            &nbsp;      Accuracy      AUC      Recall      Prec.      F1      Kappa      MCC              Fold      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;                  0      0.8148      0.8932      0.7895      0.7143      0.7500      0.6035      0.6054              1      0.7593      0.8045      0.4737      0.7500      0.5806      0.4236      0.4456              2      0.7222      0.8466      0.6316      0.6000      0.6154      0.3982      0.3985              3      0.6852      0.7278      0.6316      0.5455      0.5854      0.3338      0.3361              4      0.7778      0.8451      0.7368      0.6667      0.7000      0.5242      0.5259              5      0.8519      0.9023      0.7895      0.7895      0.7895      0.6752      0.6752              6      0.7222      0.7158      0.4737      0.6429      0.5455      0.3520      0.3605              7      0.7358      0.8079      0.5556      0.6250      0.5882      0.3948      0.3963              8      0.8113      0.8492      0.7778      0.7000      0.7368      0.5904      0.5924              9      0.7170      0.7786      0.4737      0.6429      0.5455      0.3468      0.3553              Mean      0.7597      0.8171      0.6333      0.6677      0.6437      0.4643      0.4691              Std      0.0503      0.0597      0.1276      0.0688      0.0866      0.1173      0.1152      tune_model하이퍼파라미터 튜닝을 도와주는 메서드tuned_clf_lgbm = tune_model(clf_lgbm, n_iter=10, optimize=\"Accuracy\")            &nbsp;      Accuracy      AUC      Recall      Prec.      F1      Kappa      MCC              Fold      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;                  0      0.8333      0.9308      0.8421      0.7273      0.7805      0.6473      0.6518              1      0.8148      0.8782      0.6316      0.8000      0.7059      0.5735      0.5820              2      0.8148      0.8496      0.7368      0.7368      0.7368      0.5940      0.5940              3      0.6852      0.7353      0.4211      0.5714      0.4848      0.2656      0.2720              4      0.7222      0.8226      0.6316      0.6000      0.6154      0.3982      0.3985              5      0.8333      0.8977      0.6842      0.8125      0.7429      0.6209      0.6259              6      0.7593      0.7805      0.5263      0.7143      0.6061      0.4384      0.4490              7      0.7170      0.8500      0.5556      0.5882      0.5714      0.3604      0.3607              8      0.7547      0.8492      0.5556      0.6667      0.6061      0.4301      0.4339              9      0.7170      0.7724      0.5263      0.6250      0.5714      0.3625      0.3655              Mean      0.7652      0.8366      0.6111      0.6842      0.6421      0.4691      0.4733              Std      0.0522      0.0571      0.1149      0.0826      0.0897      0.1238      0.1241      save_model학습한 모델을 저장save_model(tuned_clf_lgbm, \"./tuned_clf_lgbm\")Transformation Pipeline and Model Successfully Saved(Pipeline(memory=None,          steps=[('dtypes',                  DataTypes_Auto_infer(categorical_features=[],                                       display_types=True, features_todrop=[],                                       id_columns=[],                                       ml_usecase='classification',                                       numerical_features=[], target='Outcome',                                       time_features=[])),                 ('imputer',                  Simple_Imputer(categorical_strategy='not_available',                                 fill_value_categorical=None,                                 fill_value_numerical=None,                                 numeric_stra...                                 colsample_bytree=1.0, device='gpu',                                 feature_fraction=1.0, importance_type='split',                                 learning_rate=0.1, max_depth=-1,                                 min_child_samples=71, min_child_weight=0.001,                                 min_split_gain=0.6, n_estimators=130, n_jobs=-1,                                 num_leaves=4, objective=None, random_state=42,                                 reg_alpha=0.3, reg_lambda=4, silent='warn',                                 subsample=1.0, subsample_for_bin=200000,                                 subsample_freq=0)]],          verbose=False), './tuned_clf_lgbm.pkl')load_modelclf_lgbm = load_model(\"./tuned_clf_lgbm\")Transformation Pipeline and Model Successfully Loadedclf_lgbm[\"trained_model\"]LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',               class_weight=None, colsample_bytree=1.0, device='gpu',               feature_fraction=1.0, importance_type='split', learning_rate=0.1,               max_depth=-1, min_child_samples=71, min_child_weight=0.001,               min_split_gain=0.6, n_estimators=130, n_jobs=-1, num_leaves=4,               objective=None, random_state=42, reg_alpha=0.3, reg_lambda=4,               silent='warn', subsample=1.0, subsample_for_bin=200000,               subsample_freq=0)위와 같이 하이퍼파라미터 튜닝 목록을 확인할 수 있음"
  },
  
  {
    "title": "정형 데이터의 종류와 시각화(seaborn)",
    "url": "/posts/%EC%A0%95%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0/",
    "categories": "Artificial Intelligence, Basic",
    "tags": "seaborn, data visualization",
    "date": "2022-08-01 18:23:28 +0900",
    





    
    "snippet": "정형 데이터의 종류와 시각화데이터 시각화를 하기 전, 기본 문법을 숙지해야 한다.  평균비교 - Bar Chart  관계표현 - Scatter Plot  분포를 나타낼 때 - Histogram, Density Plot  데이터의 구성 - Stacked 100% Bar Chart, Pie ChartDEA를 위해서는 데이터가 가지고 있는 특성을 살펴보고,...",
    "content": "정형 데이터의 종류와 시각화데이터 시각화를 하기 전, 기본 문법을 숙지해야 한다.  평균비교 - Bar Chart  관계표현 - Scatter Plot  분포를 나타낼 때 - Histogram, Density Plot  데이터의 구성 - Stacked 100% Bar Chart, Pie ChartDEA를 위해서는 데이터가 가지고 있는 특성을 살펴보고, 이해한 후에 평면적인 데이터에서 주요한 특성을 설득력 있게 드러내는 가장 효과적인 수단이다.데이터의 종류정형 데이터는 크게 수치형 데이터, 범주형 데이터로 나뉜다.수치형 데이터 Numerical Data  연속형 Comtinuous Data          값이 연속된 데이터      키, 몸무게, 수입        이산형 Discrete data          정수로 딱 떨어져 셀 수 있는 데이터      과일 개수, 책의 페이지 수      범주형 데이터 Categorical Data(범주를 나눌 수 있는 데이터, 사칙연산 불가능)  순서형 Ordinal Data          순위를 매길 수 있는 데이터      학점, 순위        명목형 Nominal Data          성별, 음식 종류, 우편 번호      수치형 데이터 시각화수치형 데이터는 일정한 범위 내에서 어떻게 분포되어 있는지가 중요하다. 분포가 고르게 퍼져있을 수도, 특정 영역에 몰려 있을 수도 있다. 분포를 나타내는 “확률밀도함수”는 Unimodeal(단봉 분포)와 Bimodal(쌍봉 분포)가 있는데 쌍봉 분포는 서로 다른 특성을 갖는 두 개의 집단에 표본이 존재함으로 새로운 해설을 도출 수 있다.Seaborn에서 제공하는 주요 분포도 함수  histplot(): 히스토그램 (구간별 빈도수)  kdeplot(): 커널밀도추정 함수 그래프  displot(): 분포도 (수치형 데이터 하나의 분포를 나타냄, kaggle에서 많이 씀)  rugplot(): 러그플롯 (주변 분포를 나타냄, 다른 분포도와 사용)히스토그램# hisplotsns.histplot(data=penguins, x=\"flipper_length_mm\", bins=30)그래프를 포개지 않고 표현하려면 multiplot=’stack’을 전달한다.# hisplotsns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\")커널밀도 추정 함수 그래프커널밀도추정이 무엇인지 이해하려면 밀도추정과 커널 함수에 대해 알아야 하지만, 히스토그램에 비교해보면 좀더 매끄럽게 연결되고, 연속적이다.# kdeplotsns.kdeplot(data=tips, x=\"total_bill\", hue=\"time\", multiple=\"stack\")분포도수치형 데이터 하나의 분포를 나타내는 그래프이다. 캐글에서 분포도를 그릴 떄 displot()을 많이 사용한다. 파라미터만 조정하면 히스토그램, 커널밀도추정 함수 그래프를 모두 그릴 수 있다.# displotsns.displot(df[\"flipper_length_mm\"], kind=\"kde\")러그플롯피처가 어떻게 분포되어 있는지 작은 선분(러그)으로 표시한다.# rugplotsns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\")sns.rugplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\")범주형 데이터 시각화Seaborn에서 제공하는 함수  barplot(): 막대 그래프          범주형 데이터 값에 따라 수치형 데이터 값이 어떻게 달라지는지 파악      신뢰구간은 오차 막대 error bar 로 표현        pointplot(): 포인트플롯          범주형 데이터에 따른 수치형 데이터의 평균과 신뢰구간을 나타냄      한 화면에 여러 그래프를 그릴 때 쓰임        boxplot(): 박스플롯          막대 그래프나 포인트플롯보다 더 많은 정도      구체적으로 5가지 요약 수치를 제공        violinplot(): 바이올린플롯          박스플롯 + 커널밀도함수        conutplot(): 카운트플롯 (범주형 데이터의 개수 확인)matplotlib에서만 제공하는 파이 그래프  pie(): 파이 그래프막대 그래프범주형 데이터에 따른 수치형 데이터의 평균과 신뢰구간을 그려준다.# barplotsns.barplot(data=df, x=\"island\", y=\"body_mass_g\", errorbar=\"sd\")barplot()으로는 평균이 아닌 중앙값, 최댓값, 최솟값을 구할 수도 있다.  estimator: string or callable that maps vector -&gt; scalar, optional          Statistical function to estimate within each categorical bin.      estimator=np.median, np.max, np.min      포인트플롯막대 그래프와 동일한 정보를 제공한다. 한 화면에 여러 그래프를 그릴 때 포인트플롯을 사용하면 가독성있게 한눈에 들어온다.# pointplotsns.pointplot(data=df, x=\"sex\", y=\"bill_depth_mm\", hue=\"island\", dodge=True)박스플롯5가지 요약 수치를 제공한다.  최솟값  제1사분위 수(Q1)  제2사분위 수(Q2)  제3사분위 수(Q3)  최댓값# boxplotsns.boxplot(data=df, x=\"age\", y=\"class\")바이올린플롯박스플롯과 커널밀도추정 함수 그래프를 합쳐 놓은 그래프다. split=True를 전달하면 hue에 전달한 피처를 반으로 나누어 보여준다.# violinplotsns.violinplot(data=df, x=\"deck\", y=\"age\", hue=\"alive\", split=True)카운트플롯범주형 데이터의 개수를 확인할 때 사용하는 그래프이다. 주로 범주형 피처나 범주형 타깃값의 분포가 어떤지 파악하는 용도로 사용한다. 범주형 데이터 개수가 많을 때 x와 y의 축 방향을 바꿀 수 있다.# countplotsns.countplot(data=df, y=\"deck\", hue=\"alive\")파이 그래프평균을 비교하거나 범주형 데이터별 비율을 알아볼 떄 사용하기 좋은 그래프다. autopct 파라미터를 통해 비율을 숫자로 나타낼 수 있다.explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')fig, ax = plt.subplots()ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',        shadow=True, startangle=90)plt.show()Reference  seaborn  머신러닝·딥러닝 문제해결 전략"
  }
  
]

