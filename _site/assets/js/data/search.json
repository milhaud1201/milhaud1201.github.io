[
  
  {
    "title": "PyCaret 맛보기",
    "url": "/posts/%ED%94%BC%EB%A7%88-%EC%9D%B8%EB%94%94%EC%96%B8-with-PyCaret/",
    "categories": "Programming, Machine Learning",
    "tags": "PyCaret, Tutorial",
    "date": "2022-11-26 18:23:28 +0900",
    





    
    "snippet": "피마 인디언 데이터셋 with PyCaretimport numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltimport koreanize_matplotlibData Load피마 인디언 당뇨병 데이터 셋df_pima = pd.read_csv(\"http://bi...",
    "content": "피마 인디언 데이터셋 with PyCaretimport numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltimport koreanize_matplotlibData Load피마 인디언 당뇨병 데이터 셋df_pima = pd.read_csv(\"http://bit.ly/data-diabetes-csv\")df_pima.shape(768, 9)PyCaret당뇨병 여부 분류 문제 적용시from pycaret.classification import *setupTrain data, Test data, Label, Target 등을 설정하는 부분이며, 데이터에 전처리 기법들을 적용 할 수 있음pycaret_models = setup(    session_id=42, # 랜덤 시드    data=df_pima, # Input Data    target=\"Outcome\", # Target    normalize=True, # 정규화 여부    normalize_method=\"minmax\", # 정규화 방식    transformation=True, # 데이터의 분포가 정규 분포에 더 가까워지도록 처리    fold_strategy=\"stratifiedkfold\",    use_gpu=True)            &nbsp;      Description      Value                  0      session_id      42              1      Target      Outcome              2      Target Type      Binary              3      Label Encoded      None              4      Original Data      (768, 9)              5      Missing Values      False              6      Numeric Features      7              7      Categorical Features      1              8      Ordinal Features      False              9      High Cardinality Features      False              10      High Cardinality Method      None              11      Transformed Train Set      (537, 24)              12      Transformed Test Set      (231, 24)              13      Shuffle Train-Test      True              14      Stratify Train-Test      False              15      Fold Generator      StratifiedKFold              16      Fold Number      10              17      CPU Jobs      -1              18      Use GPU      True              19      Log Experiment      False              20      Experiment Name      clf-default-name              21      USI      d7e1              22      Imputation Type      simple              23      Iterative Imputation Iteration      None              24      Numeric Imputer      mean              25      Iterative Imputation Numeric Model      None              26      Categorical Imputer      constant              27      Iterative Imputation Categorical Model      None              28      Unknown Categoricals Handling      least_frequent              29      Normalize      True              30      Normalize Method      minmax              31      Transformation      True              32      Transformation Method      yeo-johnson              33      PCA      False              34      PCA Method      None              35      PCA Components      None              36      Ignore Low Variance      False              37      Combine Rare Levels      False              38      Rare Level Threshold      None              39      Numeric Binning      False              40      Remove Outliers      False              41      Outliers Threshold      None              42      Remove Multicollinearity      False              43      Multicollinearity Threshold      None              44      Remove Perfect Collinearity      True              45      Clustering      False              46      Clustering Iteration      None              47      Polynomial Features      False              48      Polynomial Degree      None              49      Trignometry Features      False              50      Polynomial Threshold      None              51      Group Features      False              52      Feature Selection      False              53      Feature Selection Method      classic              54      Features Selection Threshold      None              55      Feature Interaction      False              56      Feature Ratio      False              57      Interaction Threshold      None              58      Fix Imbalance      False              59      Fix Imbalance Method      SMOTE      modelsmodels_list = models()models_list                  Name      Reference      Turbo              ID                                    lr      Logistic Regression      sklearn.linear_model._logistic.LogisticRegression      True              knn      K Neighbors Classifier      sklearn.neighbors._classification.KNeighborsCl...      True              nb      Naive Bayes      sklearn.naive_bayes.GaussianNB      True              dt      Decision Tree Classifier      sklearn.tree._classes.DecisionTreeClassifier      True              svm      SVM - Linear Kernel      sklearn.linear_model._stochastic_gradient.SGDC...      True              rbfsvm      SVM - Radial Kernel      sklearn.svm._classes.SVC      False              gpc      Gaussian Process Classifier      sklearn.gaussian_process._gpc.GaussianProcessC...      False              mlp      MLP Classifier      sklearn.neural_network._multilayer_perceptron....      False              ridge      Ridge Classifier      sklearn.linear_model._ridge.RidgeClassifier      True              rf      Random Forest Classifier      sklearn.ensemble._forest.RandomForestClassifier      True              qda      Quadratic Discriminant Analysis      sklearn.discriminant_analysis.QuadraticDiscrim...      True              ada      Ada Boost Classifier      sklearn.ensemble._weight_boosting.AdaBoostClas...      True              gbc      Gradient Boosting Classifier      sklearn.ensemble._gb.GradientBoostingClassifier      True              lda      Linear Discriminant Analysis      sklearn.discriminant_analysis.LinearDiscrimina...      True              et      Extra Trees Classifier      sklearn.ensemble._forest.ExtraTreesClassifier      True              lightgbm      Light Gradient Boosting Machine      lightgbm.sklearn.LGBMClassifier      True              dummy      Dummy Classifier      sklearn.dummy.DummyClassifier      True      pycaret에서 사용 가능한 모델 목록을 확인 할 수 있음compare_modelspc_clf_models = compare_models(    n_select=25, # 반환할 모델 개수    include=models_list.index.tolist())            &nbsp;      Model      Accuracy      AUC      Recall      Prec.      F1      Kappa      MCC      TT (Sec)                  gpc      Gaussian Process Classifier      0.7710      0.8098      0.5485      0.7305      0.6223      0.4645      0.4764      0.1060              et      Extra Trees Classifier      0.7691      0.8185      0.5643      0.7206      0.6279      0.4654      0.4755      0.4720              lr      Logistic Regression      0.7653      0.8368      0.5801      0.7055      0.6320      0.4632      0.4704      0.0260              rf      Random Forest Classifier      0.7615      0.8406      0.5693      0.6962      0.6202      0.4511      0.4591      0.4840              ada      Ada Boost Classifier      0.7597      0.8199      0.6061      0.6741      0.6360      0.4580      0.4609      0.0820              lightgbm      Light Gradient Boosting Machine      0.7597      0.8174      0.6333      0.6677      0.6437      0.4643      0.4691      0.9150              lda      Linear Discriminant Analysis      0.7596      0.8319      0.5798      0.6866      0.6223      0.4501      0.4565      0.0140              rbfsvm      SVM - Radial Kernel      0.7577      0.8418      0.5263      0.7080      0.6004      0.4331      0.4445      0.0300              ridge      Ridge Classifier      0.7559      0.0000      0.5693      0.6790      0.6151      0.4405      0.4457      0.0090              gbc      Gradient Boosting Classifier      0.7541      0.8396      0.6225      0.6566      0.6332      0.4502      0.4544      0.1010              knn      K Neighbors Classifier      0.7466      0.7800      0.5424      0.6789      0.6000      0.4183      0.4262      0.3870              mlp      MLP Classifier      0.7411      0.8044      0.5860      0.6483      0.6105      0.4186      0.4230      1.6220              svm      SVM - Linear Kernel      0.7299      0.0000      0.6284      0.6121      0.6119      0.4073      0.4127      0.0090              dt      Decision Tree Classifier      0.7187      0.6909      0.5965      0.6013      0.5919      0.3799      0.3848      0.0100              nb      Naive Bayes      0.6610      0.7666      0.1123      0.4499      0.1719      0.0824      0.1127      0.0090              dummy      Dummy Classifier      0.6499      0.5000      0.0000      0.0000      0.0000      0.0000      0.0000      0.0060              qda      Quadratic Discriminant Analysis      0.5529      0.5573      0.5865      0.4949      0.4345      0.1167      0.1724      0.0090      create_model여러 모델이 아닌 하나의 모델에 대해서 setup 설정으로 학습 및 결과 확인clf_lgbm = create_model(\"lightgbm\")            &nbsp;      Accuracy      AUC      Recall      Prec.      F1      Kappa      MCC              Fold      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;                  0      0.8148      0.8932      0.7895      0.7143      0.7500      0.6035      0.6054              1      0.7593      0.8045      0.4737      0.7500      0.5806      0.4236      0.4456              2      0.7222      0.8466      0.6316      0.6000      0.6154      0.3982      0.3985              3      0.6852      0.7278      0.6316      0.5455      0.5854      0.3338      0.3361              4      0.7778      0.8451      0.7368      0.6667      0.7000      0.5242      0.5259              5      0.8519      0.9023      0.7895      0.7895      0.7895      0.6752      0.6752              6      0.7222      0.7158      0.4737      0.6429      0.5455      0.3520      0.3605              7      0.7358      0.8079      0.5556      0.6250      0.5882      0.3948      0.3963              8      0.8113      0.8492      0.7778      0.7000      0.7368      0.5904      0.5924              9      0.7170      0.7786      0.4737      0.6429      0.5455      0.3468      0.3553              Mean      0.7597      0.8171      0.6333      0.6677      0.6437      0.4643      0.4691              Std      0.0503      0.0597      0.1276      0.0688      0.0866      0.1173      0.1152      tune_model하이퍼파라미터 튜닝을 도와주는 메서드tuned_clf_lgbm = tune_model(clf_lgbm, n_iter=10, optimize=\"Accuracy\")            &nbsp;      Accuracy      AUC      Recall      Prec.      F1      Kappa      MCC              Fold      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;      &nbsp;                  0      0.8333      0.9308      0.8421      0.7273      0.7805      0.6473      0.6518              1      0.8148      0.8782      0.6316      0.8000      0.7059      0.5735      0.5820              2      0.8148      0.8496      0.7368      0.7368      0.7368      0.5940      0.5940              3      0.6852      0.7353      0.4211      0.5714      0.4848      0.2656      0.2720              4      0.7222      0.8226      0.6316      0.6000      0.6154      0.3982      0.3985              5      0.8333      0.8977      0.6842      0.8125      0.7429      0.6209      0.6259              6      0.7593      0.7805      0.5263      0.7143      0.6061      0.4384      0.4490              7      0.7170      0.8500      0.5556      0.5882      0.5714      0.3604      0.3607              8      0.7547      0.8492      0.5556      0.6667      0.6061      0.4301      0.4339              9      0.7170      0.7724      0.5263      0.6250      0.5714      0.3625      0.3655              Mean      0.7652      0.8366      0.6111      0.6842      0.6421      0.4691      0.4733              Std      0.0522      0.0571      0.1149      0.0826      0.0897      0.1238      0.1241      save_model학습한 모델을 저장save_model(tuned_clf_lgbm, \"./tuned_clf_lgbm\")Transformation Pipeline and Model Successfully Saved(Pipeline(memory=None,          steps=[('dtypes',                  DataTypes_Auto_infer(categorical_features=[],                                       display_types=True, features_todrop=[],                                       id_columns=[],                                       ml_usecase='classification',                                       numerical_features=[], target='Outcome',                                       time_features=[])),                 ('imputer',                  Simple_Imputer(categorical_strategy='not_available',                                 fill_value_categorical=None,                                 fill_value_numerical=None,                                 numeric_stra...                                 colsample_bytree=1.0, device='gpu',                                 feature_fraction=1.0, importance_type='split',                                 learning_rate=0.1, max_depth=-1,                                 min_child_samples=71, min_child_weight=0.001,                                 min_split_gain=0.6, n_estimators=130, n_jobs=-1,                                 num_leaves=4, objective=None, random_state=42,                                 reg_alpha=0.3, reg_lambda=4, silent='warn',                                 subsample=1.0, subsample_for_bin=200000,                                 subsample_freq=0)]],          verbose=False), './tuned_clf_lgbm.pkl')load_modelclf_lgbm = load_model(\"./tuned_clf_lgbm\")Transformation Pipeline and Model Successfully Loadedclf_lgbm[\"trained_model\"]LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',               class_weight=None, colsample_bytree=1.0, device='gpu',               feature_fraction=1.0, importance_type='split', learning_rate=0.1,               max_depth=-1, min_child_samples=71, min_child_weight=0.001,               min_split_gain=0.6, n_estimators=130, n_jobs=-1, num_leaves=4,               objective=None, random_state=42, reg_alpha=0.3, reg_lambda=4,               silent='warn', subsample=1.0, subsample_for_bin=200000,               subsample_freq=0)위와 같이 하이퍼파라미터 튜닝 목록을 확인할 수 있음"
  },
  
  {
    "title": "API를 활용한 LA의 범죄 사건과 피해자 유형 파악과 3D 인터렉티브 맵 시각화",
    "url": "/posts/API%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-LA%EC%9D%98-%EB%B2%94%EC%A3%84-%EC%82%AC%EA%B1%B4%EA%B3%BC-%ED%94%BC%ED%95%B4%EC%9E%90-%EC%9C%A0%ED%98%95-%ED%8C%8C%EC%95%85%EA%B3%BC-3D-%EC%9D%B8%ED%84%B0%EB%A0%89%ED%8B%B0%EB%B8%8C-%EB%A7%B5-%EC%8B%9C%EA%B0%81%ED%99%94/",
    "categories": "Data Science, Streamlit",
    "tags": "data science, streamlit, data visualization",
    "date": "2022-08-04 18:23:28 +0900",
    





    
    "snippet": "Stremlit이란?데이터 과학자들이 데이터 시각화, 머신러닝 모델링, 웹 애플리케이션 등을 쉽게 만들 수 있도록 도와주는 오픈소스 라이브러리이다. Streamlit을 사용하면 파이썬 코드만으로 웹 애플리케이션을 만들 수 있어서, 데이터 분석과 모델링 결과를 공유하거나 인터랙티브한 대시보드를 만드는 등 다양한 용도로 활용할 수 있다. 애플리케이션은 웹...",
    "content": "Stremlit이란?데이터 과학자들이 데이터 시각화, 머신러닝 모델링, 웹 애플리케이션 등을 쉽게 만들 수 있도록 도와주는 오픈소스 라이브러리이다. Streamlit을 사용하면 파이썬 코드만으로 웹 애플리케이션을 만들 수 있어서, 데이터 분석과 모델링 결과를 공유하거나 인터랙티브한 대시보드를 만드는 등 다양한 용도로 활용할 수 있다. 애플리케이션은 웹 브라우저에서 실행되며, 파이썬 코드와 함께 작동하기 때문에 개발자들이 쉽게 웹 애플리케이션을 구축할 수 있다.간단한 사용법 알아보기# app.pyimport streamlit as stst.title(\"Hello world\")터미널에서 아래의 코드를 입력하면 다음과 같이 로컬호스트 서버가 실행된다.streamlit run app.pyYou can now view your Streamlit app in your browser.Local URL: http://localhost:8501   Network URL: http://192.168.0.5:8501  streamlit은 markdown 문법을 지원한다.# app.pyimport streamlit as stst.title(\"Hello world\")st.markdown(\"# My first streamlit dashboard!\")st.markdown(\"## My first streamlit dashboard!\")st.markdown(\"### My first streamlit dashboard!\")st.markdown(\"* 안녕하세요 _Milhuad_ 입니다.\")st.markdown(\"* 안녕하세요 **Milhuad** 입니다.\")st.markdown(\"* 안녕하세요 `Milhuad` 입니다.\")Task 1Crime Data from 2020 to Present 로드하기  데이터프레임의 date_rptd 컬럼을 pop part 해서 pandas의 date/time 형식으로 변환한다.  경도와 위도의 결측값은 3차원 지도 시각에서 깨질 것이기에  dropna 한다.import streamlit as stimport pandas as pdimport numpy as np# API EndpointDATA_URL = (\t\"https://data.lacity.org/resource/2nrs-mtv8.csv?$query=SELECT%0A%20%20%60dr_no%60%2C%0A%20%20%60date_rptd%60%2C%0A%20%20%60date_occ%60%2C%0A%20%20%60time_occ%60%2C%0A%20%20%60area%60%2C%0A%20%20%60area_name%60%2C%0A%20%20%60rpt_dist_no%60%2C%0A%20%20%60part_1_2%60%2C%0A%20%20%60crm_cd%60%2C%0A%20%20%60crm_cd_desc%60%2C%0A%20%20%60mocodes%60%2C%0A%20%20%60vict_age%60%2C%0A%20%20%60vict_sex%60%2C%0A%20%20%60vict_descent%60%2C%0A%20%20%60premis_cd%60%2C%0A%20%20%60premis_desc%60%2C%0A%20%20%60weapon_used_cd%60%2C%0A%20%20%60weapon_desc%60%2C%0A%20%20%60status%60%2C%0A%20%20%60status_desc%60%2C%0A%20%20%60crm_cd_1%60%2C%0A%20%20%60crm_cd_2%60%2C%0A%20%20%60crm_cd_3%60%2C%0A%20%20%60crm_cd_4%60%2C%0A%20%20%60location%60%2C%0A%20%20%60cross_street%60%2C%0A%20%20%60lat%60%2C%0A%20%20%60lon%60\")st.title(\"Incidents of crime in the City of LA\")st.markdown(\"Streamlit dashboard를 이용한 LA의 범죄 사건 Application 🚗💥\")# row개수에 따라 데이터 보여주기@st.cache(persist=True)def load_data(nrows):\tdata = pd.read_csv(DATA_URL, nrows=nrows, parse_dates=['date_rptd'])\tdata = data.dropna(subset=['lat', 'lon'])\tlowercase = lambda x: str(x).lower()\tdata = data.rename(lowercase, axis='columns')\tdata = data.sort_values(by='date_rptd', ascending=False)\treturn datadata = load_data(100000)if st.checkbox(\"Show Raw Data\", False):\tst.subheader('Raw Data')\tst.write(data)체크박스 유무에 따라 데이터 프레임을 보여준다.Task 2데이터 지도 시각화하기st.header(\"Where is the most place for crime in LA?\")crime = st.slider(\"Number of crime in LA\", 0, 19)st.map(data.query(\"area &gt;= @crime\")[['lat', 'lon']].dropna(how='any'))Task 3  데이터 필터링, 인터렉티브 테이블  3D 인터렉티브 맵 위에 전처리한 데이터 Plot 그리기import pydeck as pdkst.header(\"What is the number of victims by age?\")age_range = st.slider(\"Victims by age to look at\", 0, 100, (0, 100))data = data[(data['vict_age'] &gt;= age_range[0]) &amp; (data['vict_age'] &lt;= age_range[1])]st.markdown(\"희생자의 나이는 %i부터 %i까지입니다\" % (age_range[0], age_range[1]))st.markdown(\"총 %i명 입니다\" % len(data))midpoint = (np.average(data['lat']), np.average(data['lon']))st.write(pdk.Deck(\tmap_style=\"mapbox://styles/mapbox/light-v9\",\tinitial_view_state={\t\t\"latitude\": midpoint[0],\t\t\"longitude\": midpoint[1],\t\t\"zoom\": 11,\t\t\"pitch\": 50,\t},\tlayers=[\t\tpdk.Layer(\t\t\"HexagonLayer\", \t\tdata=data[['vict_age', 'lat', 'lon']],\t\tget_position=['lon', 'lat'],\t\tradius=100,\t\textruded=True,\t\tpickable=True,\t\televation_scale=4,\t\televation_range=[0, 1000],\t\t),\t],))Task 5  차트 그리기          데이터 프레임 정의하기      groupby로 count할 데이터 그룹핑하기      plotly express bar로 count bar plot 그리기        st.subheader(\"The number of victims by descent and sex\")chart_data = pd.DataFrame({  'crime_cd': data['crm_cd'],  'type': data['crm_cd_desc'],  'descent': data['vict_descent'],  'sex': data['vict_sex'],})chart_data = chart_data.groupby(by=['descent', 'sex']).size().reset_index(name='counts')fig = px.bar(chart_data, x='descent', y='counts' , color='sex', barmode='group', height=800)# fig.update_layout(yaxis={'categoryorder':'total ascending'})st.write(fig)                            Task 6드롭 다운을 사용하여 데이터 선택하기st.header(\"Top 5 type of crimes\")select = st.selectbox('The types of crimes &amp; area', \t['Vehicle - Stolen', 'Battery - Simple assault', 'Theft of identity', 'Burglary from vehicle', 'Andalism - Felony'])if select == 'Vehicle - Stolen':\tst.write(data.query(\"crm_cd_desc == 'VEHICLE - STOLEN'\")[[\"crm_cd_desc\", \"area_name\", \"premis_desc\"]].sort_values(by=[\"crm_cd_desc\"], ascending=False).dropna(how='any'), width=1000)elif select == 'Battery - Simple assault':\tst.write(data.query(\"crm_cd_desc == 'BATTERY - SIMPLE ASSAULT'\")[[\"crm_cd_desc\", \"area_name\", \"premis_desc\"]].sort_values(by=[\"crm_cd_desc\"], ascending=False).dropna(how='any'), width=1000)elif select == 'Theft of identity':\tst.write(data.query(\"crm_cd_desc == 'THEFT OF IDENTITY'\")[[\"crm_cd_desc\", \"area_name\", \"premis_desc\"]].sort_values(by=[\"crm_cd_desc\"], ascending=False).dropna(how='any'), width=1000)elif select == 'Burglary from vehicle':\tst.write(data.query(\"crm_cd_desc == 'BURGLARY FROM VEHICLE'\")[[\"crm_cd_desc\", \"area_name\", \"premis_desc\"]].sort_values(by=[\"crm_cd_desc\"], ascending=False).dropna(how='any'), width=1000)elif select == 'Andalism - Felony':\tst.write(data.query(\"crm_cd_desc == 'VANDALISM - FELONY ($400 &amp; OVER, ALL CHURCH VANDALISMS)'\")[[\"crm_cd_desc\", \"area_name\", \"premis_desc\"]].sort_values(by=[\"crm_cd_desc\"], ascending=False).dropna(how='any'), width=1000)데이터 로드와 간단한 데이터 전처리, 3D 지도 시각화, Bar chart를 그렸다. 본 글에서 데이터 전처리에 대한 디테일은 조금 떨어지지만, 이정도만 알아도 streamlit을 다루기엔 충분하다.데모 영상과 전체 코드는 여기에 있습니다.Reference  Crime Data from 2020 to Present          Data Provided by Los Angeles Police Department      "
  },
  
  {
    "title": "Sound와 Waveforms",
    "url": "/posts/Sound%EC%99%80-Waveforms/",
    "categories": "Audio Signal Processing",
    "tags": "audio signal, deep learning",
    "date": "2022-08-04 18:23:28 +0900",
    





    
    "snippet": "[Input Representation] Sound와 WaveformsSound소리가 잘 들리는 것은 물체를 진동시켜 소리가 생성되므로 이러한 물체가 진동하고 진동으로 인해 공기 분자가 진동하고 서로 부딪히면서 기압의 상태를 변화시켜 파동을 만들어 낸다. Air molecules를 통해 한 지점에서 다른 지점으로 에너지를 전달한다. Sound wave...",
    "content": "[Input Representation] Sound와 WaveformsSound소리가 잘 들리는 것은 물체를 진동시켜 소리가 생성되므로 이러한 물체가 진동하고 진동으로 인해 공기 분자가 진동하고 서로 부딪히면서 기압의 상태를 변화시켜 파동을 만들어 낸다. Air molecules를 통해 한 지점에서 다른 지점으로 에너지를 전달한다. Sound wave나 Mechanical wave가 있을 때, 매개는 형태를 가지며 그 형태는 소리에서 어떤 일이 일어나는 것처럼 보인다.-&gt; Pressure plot을 사용하여 이 모든 것을 시각화할 수 있다.WaveformPressure plot로 Waveform 이용한 복잡한 Sound를 표현할 수 있다.  어떤 노이즈가 있더라고 음악 전체를 나타낼 수 있다.Waveform 정보  주파수 Frequency  강도 Intensity  음색 TimbreCents  Octave divided in 1200 cents  100 cents in a semitone  Noticeable pitch difference: 10-25 centsSound Intensity 사운드 강도      사람의 가청 범위$TOH = 10^{-12}W/M^2$        The Threshold of Hearing and the Decibel Scale (청력의 임계값과 데시벨 척도)              Source      Intensity      Intensity Level                  Threshold of Hearing (TOH)      1*10-12 W/m2      0 dB              Rustling Leaves      1*10-11 W/m2      10 dB              Whisper      1*10-10 W/m2      20 dB              Normal      Conversation      1*10-6 W/m2\t60 dB      Intensity level  Logarithmic scale  Measured in decibels (dB)  Ration between two intensity values  Use an intensity of reference (TOH)$dB(I) = 10 * log_10$Loudness 음량인간 청각의 지각 정도에 의해 느끼는 소리의 크기(심리량)Timbre 음색바이올린과 트럼펫은 비슷한 Intensity로 연주하지만 우리가 두 악기의 소리가 다르다고 느끼는 건 음색이 다르기 때문이다.음색의 특징  Timbre is multidimensional  Sound envelope  Harmonic content  Amplitude / frequency modulationSound envelope  Attack-Decay-Sustain-Release ModelAmplitude modulator  현악기 트레몰로 (주파수가 아닌 진폭의 변화)  Periodic variation in amplitude  In music, used for expressive purposesReference  MATLAB - 음성 신호의 피크 포락선"
  },
  
  {
    "title": "ML에서의 오디오 신호 처리 영역",
    "url": "/posts/ML%EC%97%90%EC%84%9C%EC%9D%98-%EC%98%A4%EB%94%94%EC%98%A4-%EC%8B%A0%ED%98%B8-%EC%B2%98%EB%A6%AC-%EC%98%81%EC%97%AD/",
    "categories": "Audio Signal Processing",
    "tags": "audio signal, deep learning",
    "date": "2022-08-02 18:23:28 +0900",
    





    
    "snippet": "ML에서의 오디오 신호 처리 영역어떤 문제를 해결 할 수 있는가ML에서 Audio digital signal processing은 어떻게 쓰일까?  Audio classification  Speech recognition / speaker verification  Audio denoising / audio upsampling  Music Informa...",
    "content": "ML에서의 오디오 신호 처리 영역어떤 문제를 해결 할 수 있는가ML에서 Audio digital signal processing은 어떻게 쓰일까?  Audio classification  Speech recognition / speaker verification  Audio denoising / audio upsampling  Music Information Retrieval          Music Instruemnt Classification      Mood classification      …        …먼저 알아야 할 것이러한 문제해결을 위해서는 Sound Wave와 Digital to Analog converters 등의 지식이 필요하다.  Sound Waves  DAC / ADC  Time- and frequency-domain audio features (rns, spectral centroid)  Audio transformations          푸리에 변환 / STFT      Constant-Q Transform      Mel Spectrogram      Chromograms      필요한 기술 스택  python  librosaReferences  musikalkemist/AudioSignalProcessingForML"
  },
  
  {
    "title": "정형 데이터의 종류와 시각화(seaborn)",
    "url": "/posts/%EC%A0%95%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0/",
    "categories": "Artificial Intelligence, Basic",
    "tags": "seaborn, data visualization",
    "date": "2022-08-01 18:23:28 +0900",
    





    
    "snippet": "정형 데이터의 종류와 시각화데이터 시각화를 하기 전, 기본 문법을 숙지해야 한다.  평균비교 - Bar Chart  관계표현 - Scatter Plot  분포를 나타낼 때 - Histogram, Density Plot  데이터의 구성 - Stacked 100% Bar Chart, Pie ChartDEA를 위해서는 데이터가 가지고 있는 특성을 살펴보고,...",
    "content": "정형 데이터의 종류와 시각화데이터 시각화를 하기 전, 기본 문법을 숙지해야 한다.  평균비교 - Bar Chart  관계표현 - Scatter Plot  분포를 나타낼 때 - Histogram, Density Plot  데이터의 구성 - Stacked 100% Bar Chart, Pie ChartDEA를 위해서는 데이터가 가지고 있는 특성을 살펴보고, 이해한 후에 평면적인 데이터에서 주요한 특성을 설득력 있게 드러내는 가장 효과적인 수단이다.데이터의 종류정형 데이터는 크게 수치형 데이터, 범주형 데이터로 나뉜다.수치형 데이터 Numerical Data  연속형 Comtinuous Data          값이 연속된 데이터      키, 몸무게, 수입        이산형 Discrete data          정수로 딱 떨어져 셀 수 있는 데이터      과일 개수, 책의 페이지 수      범주형 데이터 Categorical Data(범주를 나눌 수 있는 데이터, 사칙연산 불가능)  순서형 Ordinal Data          순위를 매길 수 있는 데이터      학점, 순위        명목형 Nominal Data          성별, 음식 종류, 우편 번호      수치형 데이터 시각화수치형 데이터는 일정한 범위 내에서 어떻게 분포되어 있는지가 중요하다. 분포가 고르게 퍼져있을 수도, 특정 영역에 몰려 있을 수도 있다. 분포를 나타내는 “확률밀도함수”는 Unimodeal(단봉 분포)와 Bimodal(쌍봉 분포)가 있는데 쌍봉 분포는 서로 다른 특성을 갖는 두 개의 집단에 표본이 존재함으로 새로운 해설을 도출 수 있다.Seaborn에서 제공하는 주요 분포도 함수  histplot(): 히스토그램 (구간별 빈도수)  kdeplot(): 커널밀도추정 함수 그래프  displot(): 분포도 (수치형 데이터 하나의 분포를 나타냄, kaggle에서 많이 씀)  rugplot(): 러그플롯 (주변 분포를 나타냄, 다른 분포도와 사용)히스토그램# hisplotsns.histplot(data=penguins, x=\"flipper_length_mm\", bins=30)그래프를 포개지 않고 표현하려면 multiplot=’stack’을 전달한다.# hisplotsns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\")커널밀도 추정 함수 그래프커널밀도추정이 무엇인지 이해하려면 밀도추정과 커널 함수에 대해 알아야 하지만, 히스토그램에 비교해보면 좀더 매끄럽게 연결되고, 연속적이다.# kdeplotsns.kdeplot(data=tips, x=\"total_bill\", hue=\"time\", multiple=\"stack\")분포도수치형 데이터 하나의 분포를 나타내는 그래프이다. 캐글에서 분포도를 그릴 떄 displot()을 많이 사용한다. 파라미터만 조정하면 히스토그램, 커널밀도추정 함수 그래프를 모두 그릴 수 있다.# displotsns.displot(df[\"flipper_length_mm\"], kind=\"kde\")러그플롯피처가 어떻게 분포되어 있는지 작은 선분(러그)으로 표시한다.# rugplotsns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\")sns.rugplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\")범주형 데이터 시각화Seaborn에서 제공하는 함수  barplot(): 막대 그래프          범주형 데이터 값에 따라 수치형 데이터 값이 어떻게 달라지는지 파악      신뢰구간은 오차 막대 error bar 로 표현        pointplot(): 포인트플롯          범주형 데이터에 따른 수치형 데이터의 평균과 신뢰구간을 나타냄      한 화면에 여러 그래프를 그릴 때 쓰임        boxplot(): 박스플롯          막대 그래프나 포인트플롯보다 더 많은 정도      구체적으로 5가지 요약 수치를 제공        violinplot(): 바이올린플롯          박스플롯 + 커널밀도함수        conutplot(): 카운트플롯 (범주형 데이터의 개수 확인)matplotlib에서만 제공하는 파이 그래프  pie(): 파이 그래프막대 그래프범주형 데이터에 따른 수치형 데이터의 평균과 신뢰구간을 그려준다.# barplotsns.barplot(data=df, x=\"island\", y=\"body_mass_g\", errorbar=\"sd\")barplot()으로는 평균이 아닌 중앙값, 최댓값, 최솟값을 구할 수도 있다.  estimator: string or callable that maps vector -&gt; scalar, optional          Statistical function to estimate within each categorical bin.      estimator=np.median, np.max, np.min      포인트플롯막대 그래프와 동일한 정보를 제공한다. 한 화면에 여러 그래프를 그릴 때 포인트플롯을 사용하면 가독성있게 한눈에 들어온다.# pointplotsns.pointplot(data=df, x=\"sex\", y=\"bill_depth_mm\", hue=\"island\", dodge=True)박스플롯5가지 요약 수치를 제공한다.  최솟값  제1사분위 수(Q1)  제2사분위 수(Q2)  제3사분위 수(Q3)  최댓값# boxplotsns.boxplot(data=df, x=\"age\", y=\"class\")바이올린플롯박스플롯과 커널밀도추정 함수 그래프를 합쳐 놓은 그래프다. split=True를 전달하면 hue에 전달한 피처를 반으로 나누어 보여준다.# violinplotsns.violinplot(data=df, x=\"deck\", y=\"age\", hue=\"alive\", split=True)카운트플롯범주형 데이터의 개수를 확인할 때 사용하는 그래프이다. 주로 범주형 피처나 범주형 타깃값의 분포가 어떤지 파악하는 용도로 사용한다. 범주형 데이터 개수가 많을 때 x와 y의 축 방향을 바꿀 수 있다.# countplotsns.countplot(data=df, y=\"deck\", hue=\"alive\")파이 그래프평균을 비교하거나 범주형 데이터별 비율을 알아볼 떄 사용하기 좋은 그래프다. autopct 파라미터를 통해 비율을 숫자로 나타낼 수 있다.explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')fig, ax = plt.subplots()ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',        shadow=True, startangle=90)plt.show()Reference  seaborn  머신러닝·딥러닝 문제해결 전략"
  }
  
]

